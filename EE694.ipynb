{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AIo83rp1J53"
   },
   "source": [
    "import dependencies to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1A1Oi95x1Esq",
    "outputId": "e3cac1ef-00b4-4b63-efa8-72ecdfb6baa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /home/ardhendu/miniconda3/lib/python3.12/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torchmetrics) (2.2.5)\n",
      "Requirement already satisfied: packaging>17.1 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torchmetrics) (2.7.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: setuptools in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.8.0)\n",
      "Requirement already satisfied: typing_extensions in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ardhendu/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "import torch\n",
    "print(torch.cuda.is_available())  \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import utils\n",
    "from torch import optim\n",
    "from torch import device\n",
    "from torch import inference_mode\n",
    "import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import ConfusionMatrix\n",
    "import mlxtend\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import numpy\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-_1ocEh12bV"
   },
   "source": [
    "import data,info,evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxVEEknu11ks",
    "outputId": "06bbc342-3c9a-484b-97e6-fea01921f4f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medmnist\n",
      "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.2.1)\n",
      "Collecting fire (from medmnist)\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.21.0+cu124)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (1.15.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.3.30)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (4.13.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
      "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=dd3ed26b0970e49e772d91d8dfb9e44d3322ba788eb10056fd89dcd995d2a92b\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
      "Successfully built fire\n",
      "Installing collected packages: fire, medmnist\n",
      "Successfully installed fire-0.7.0 medmnist-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmlWV0l61z_f"
   },
   "source": [
    "Download data from official source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uENT6oBm5awo"
   },
   "source": [
    "which Device to be used for training and evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oLKZaFHV5bTH"
   },
   "outputs": [],
   "source": [
    "# set device agnostic code\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WUNin4GV2XwE"
   },
   "outputs": [],
   "source": [
    "# download and load data from official source\n",
    "data_flag = 'pathmnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "# Define data transformations\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# Load the full dataset\n",
    "full_dataset = DataClass(split='train', transform=data_transform, download=True)\n",
    "\n",
    "train_data = DataClass(split='train', transform=data_transform, download=True)\n",
    "val_data = DataClass(split='val', transform=data_transform, download=True)\n",
    "test_data = DataClass(split='test', transform=data_transform, download=True)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.7 * total_size)  # 70% for training\n",
    "test_size = int(0.2 * total_size)   # 20% for testing\n",
    "val_size = total_size - train_size - test_size  # Remaining 10% for validation\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "#train_data, test_data, val_data = random_split(full_dataset, [train_size, test_size, val_size])\n",
    "\n",
    "# Load the test dataset separately\n",
    "#test_data = DataClass(split='test', transform=data_transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDnhBl1hAE_g",
    "outputId": "ec51f17e-8e22-46c2-86e2-25dd9a7e603f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataset.Subset at 0x7e2dfebc3650>,\n",
       " Dataset PathMNIST of size 28 (pathmnist)\n",
       "     Number of datapoints: 7180\n",
       "     Root location: /root/.medmnist\n",
       "     Split: test\n",
       "     Task: multi-class\n",
       "     Number of channels: 3\n",
       "     Meaning of labels: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
       "     Number of samples: {'train': 89996, 'val': 10004, 'test': 7180}\n",
       "     Description: The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.\n",
       "     License: CC BY 4.0,\n",
       " <torch.utils.data.dataset.Subset at 0x7e2cf933df90>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qXCtvyHANPy",
    "outputId": "939c4341-a836-481d-a6b9-9f5c436e1e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:\n",
      " tensor([[[ 0.7882,  0.4353,  0.0196,  ...,  0.4431,  0.4667,  0.5686],\n",
      "         [ 0.5451,  0.4118,  0.3725,  ...,  0.6941,  0.7255,  0.7255],\n",
      "         [ 0.3412,  0.3725,  0.4431,  ...,  0.7098,  0.6941,  0.6627],\n",
      "         ...,\n",
      "         [ 0.6314,  0.6471,  0.5686,  ...,  0.6549,  0.5216,  0.4196],\n",
      "         [ 0.6000,  0.6471,  0.7333,  ...,  0.6392,  0.6471,  0.5451],\n",
      "         [ 0.6471,  0.6157,  0.5216,  ...,  0.5922,  0.6078,  0.6706]],\n",
      "\n",
      "        [[ 0.6157,  0.1608, -0.2784,  ..., -0.1686, -0.1294, -0.0275],\n",
      "         [ 0.0745, -0.0353, -0.0745,  ...,  0.0745,  0.1608,  0.1451],\n",
      "         [-0.1608, -0.1373, -0.0745,  ...,  0.1451,  0.1216,  0.0667],\n",
      "         ...,\n",
      "         [ 0.2392,  0.2000,  0.0902,  ...,  0.0431, -0.0745, -0.2000],\n",
      "         [ 0.1922,  0.2941,  0.4510,  ...,  0.1843,  0.1922,  0.0431],\n",
      "         [ 0.2549,  0.2078,  0.0745,  ...,  0.0275,  0.0196,  0.0510]],\n",
      "\n",
      "        [[ 0.7725,  0.4588,  0.1059,  ...,  0.2784,  0.3098,  0.3882],\n",
      "         [ 0.4353,  0.3725,  0.3333,  ...,  0.4588,  0.5137,  0.5059],\n",
      "         [ 0.2784,  0.2941,  0.3333,  ...,  0.5059,  0.4824,  0.4510],\n",
      "         ...,\n",
      "         [ 0.5373,  0.5216,  0.4431,  ...,  0.4353,  0.3569,  0.2627],\n",
      "         [ 0.5059,  0.5765,  0.6784,  ...,  0.5216,  0.5373,  0.4431],\n",
      "         [ 0.5451,  0.5216,  0.4510,  ...,  0.4039,  0.3961,  0.4353]]])\n",
      "Label:\n",
      " [5]\n",
      "Image shape: torch.Size([3, 28, 28])\n",
      "Label: [5]\n"
     ]
    }
   ],
   "source": [
    "# check data properties\n",
    "img = train_data[0][0]\n",
    "label = train_data[0][1]\n",
    "\n",
    "print(f\"Image:\\n {img}\")\n",
    "print(f\"Label:\\n {label}\")\n",
    "\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1P8wCHBtAfdc",
    "outputId": "13b1e6f5-e641-4feb-c67f-fae55575a459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of channels: 3\n",
      "number of classes: 9\n",
      "class names: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n"
     ]
    }
   ],
   "source": [
    "# Number of image channels\n",
    "n_channels = info['n_channels']\n",
    "print(f\"number of channels: {n_channels}\")\n",
    "\n",
    "# Number of classes\n",
    "n_classes = len(info['label'])\n",
    "print(f\"number of classes: {n_classes}\")\n",
    "\n",
    "# Get the class names from the dataset\n",
    "class_names = info['label']\n",
    "print(f\"class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u19xz0k3Amyh",
    "outputId": "56f1a6a1-7ef6-49a0-ec43-116403ef08c4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# check data images\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m[i][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     label \u001b[38;5;241m=\u001b[39m train_data[i][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# check data images\n",
    "for i in range(5):\n",
    "    img = train_data[i][0]\n",
    "    label = train_data[i][1]\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.title(label)\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6KpQbFrJA8Sr"
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders for efficient batching\n",
    "BATCH_SIZE = 64\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-zq6TIiBDvD",
    "outputId": "73a2399a-e7b0-4fc9-b791-55b73a4526f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7e2cf1d54510>, <torch.utils.data.dataloader.DataLoader object at 0x7e2cf1d4d8d0>)\n",
      "Length of train dataloader: 985 batches of 64\n",
      "Length of test dataloader: 113 batches of 64\n",
      "Length of val dataloader: 141 batches of 64\n"
     ]
    }
   ],
   "source": [
    "# check dataloader\n",
    "print(f\"Dataloaders: {train_loader, test_loader}\")\n",
    "print(f\"Length of train dataloader: {len(train_loader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_loader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of val dataloader: {len(val_loader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAg1GWZXB-36"
   },
   "source": [
    "Get a batch from the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-m4po2EsB-I1",
    "outputId": "da468d9a-9f28-4372-d04a-c91520dfe510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 28, 28])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "#. Split the batch into features and labels:\n",
    "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
    "\n",
    "#. Split the batch into features and labels:\n",
    "train_features_batch, train_labels_batch = next(iter(train_loader))\n",
    "\n",
    "#Check the shape of the features tensor:\n",
    "print(train_features_batch.shape)\n",
    "\n",
    "#shape of label\n",
    "print(train_labels_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6DTmaVHwEhTp"
   },
   "outputs": [],
   "source": [
    "# define training loop functions\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # need to change target shape for this medmnist data\n",
    "        y = y.squeeze().long()\n",
    "\n",
    "        # Send data to selected device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. loss and accuracy\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PVc8wBAGEyzJ"
   },
   "outputs": [],
   "source": [
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval() # eval mode for testing\n",
    "    with torch.inference_mode(): # Inference context manager\n",
    "        for X, y in data_loader:\n",
    "            # need to change target shape for this medmnist data\n",
    "            y = y.squeeze().long()\n",
    "\n",
    "            # Send data to selected device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "        return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "j0hlrGutHLjl"
   },
   "outputs": [],
   "source": [
    "def eval_func(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "\n",
    "    eval_loss, eval_acc = 0, 0\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "    y_targets = []\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in tqdm(enumerate(data_loader)):\n",
    "            # need to change target shape for this medmnist data\n",
    "            y = y.squeeze().long()\n",
    "\n",
    "            # Send data to selected device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            eval_pred = model(X)\n",
    "\n",
    "            # Find loss and accuracy\n",
    "            eval_loss += loss_fn(eval_pred, y)\n",
    "            eval_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred=eval_pred.argmax(dim=1))\n",
    "\n",
    "            # Add prediction and target labels to list\n",
    "            eval_labels = torch.argmax(torch.softmax(eval_pred, dim=1), dim=1)\n",
    "            y_preds.append(eval_labels)\n",
    "            y_targets.append(y)\n",
    "\n",
    "        # Scale loss and acc\n",
    "        eval_loss /= len(data_loader)\n",
    "        eval_acc /= len(data_loader)\n",
    "\n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds=torch.cat(y_preds).cpu()\n",
    "        y_targets=torch.cat(y_targets).cpu()\n",
    "\n",
    "        return {\"model_name\": model.__class__.__name__,\n",
    "                \"loss\": eval_loss.item(),\n",
    "                \"accuracy\": eval_acc,\n",
    "                \"predictions\": y_preds,\n",
    "                \"targets\": y_targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IuoodyCtHu_i"
   },
   "outputs": [],
   "source": [
    "# function to calculate model run time\n",
    "\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nwO-MG8yHxHj"
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "hq5LmkkeH3lJ",
    "outputId": "5e6c2f3c-0c9d-4739-9978-270754b580f5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_channels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Define Model\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m model \u001b[38;5;241m=\u001b[39m cnn(input_shape\u001b[38;5;241m=\u001b[39m\u001b[43mn_channels\u001b[49m, \n\u001b[1;32m     65\u001b[0m                      hidden_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     66\u001b[0m                      output_shape\u001b[38;5;241m=\u001b[39mn_classes,n_classes\u001b[38;5;241m=\u001b[39mn_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Setup loss and optimizer\u001b[39;00m\n\u001b[1;32m     70\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_channels' is not defined"
     ]
    }
   ],
   "source": [
    "class cnn(torch.nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int,n_classes: int):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3),\n",
    "            nn.BatchNorm2d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, \n",
    "                         stride=2))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units*4, \n",
    "                      kernel_size=3),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units*4, \n",
    "                      out_channels=hidden_units*4, \n",
    "                      kernel_size=3),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units*4, \n",
    "                      out_channels=hidden_units*4, \n",
    "                      kernel_size=3,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(hidden_units*4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, \n",
    "                         stride=2))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_units*4 * 4 * 4, hidden_units*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units*8, hidden_units*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units*8, self.n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# Define Model\n",
    "model = cnn(input_shape=n_channels, \n",
    "                     hidden_units=16,\n",
    "                     output_shape=n_classes,n_classes=n_classes).to(device)\n",
    "\n",
    "\n",
    "# Setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# View Model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "p4WRiegyIN9y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# call train and test function\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m---> 16\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m(data_loader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     17\u001b[0m                                        model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m                                        loss_fn \u001b[38;5;241m=\u001b[39m loss_fn,\n\u001b[1;32m     19\u001b[0m                                        optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     20\u001b[0m                                        accuracy_fn\u001b[38;5;241m=\u001b[39maccuracy_fn,\n\u001b[1;32m     21\u001b[0m                                        device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     23\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(data_loader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m     24\u001b[0m                                     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     25\u001b[0m                                     loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m     26\u001b[0m                                     accuracy_fn\u001b[38;5;241m=\u001b[39maccuracy_fn,\n\u001b[1;32m     27\u001b[0m                                     device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_step' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure Time\n",
    "\n",
    "train_time_start_model = timer()\n",
    "\n",
    "iteration_loss_list = []\n",
    "iteration_accuracy_list = []\n",
    "\n",
    "# set parameters\n",
    "epochs = 10\n",
    "best_loss = 10\n",
    "\n",
    "# call train and test function\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc = train_step(data_loader=train_dataloader,\n",
    "                                       model=model,\n",
    "                                       loss_fn = loss_fn,\n",
    "                                       optimizer=optimizer,\n",
    "                                       accuracy_fn=accuracy_fn,\n",
    "                                       device=device)\n",
    "\n",
    "    test_loss, test_acc = test_step(data_loader=test_dataloader,\n",
    "                                    model=model,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    accuracy_fn=accuracy_fn,\n",
    "                                    device=device)\n",
    "\n",
    "    for iteration, (x, y) in enumerate(train_dataloader):\n",
    "        iteration_loss_list.append(train_loss.item())\n",
    "        iteration_accuracy_list.append(train_acc)\n",
    "\n",
    "\n",
    "    print(f\"Epoch: {epoch} | Training loss: {train_loss:.3f} | Training acc: {train_acc:.2f} | Test loss: {test_loss:.3f} | Test acc: {test_acc:.2f}\")\n",
    "\n",
    "    # save best model instance\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        print(f\"Saving best model for epoch: {epoch}\")\n",
    "        torch.save(obj=model.state_dict(),\n",
    "                   f=\"./model.pth\")\n",
    "\n",
    "\n",
    "train_time_end_model = timer()\n",
    "total_train_time_model = print_train_time(start=train_time_start_model,\n",
    "                                           end=train_time_end_model,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xV9jB79IScj"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "loaded_model = cnn(input_shape=n_channels,\n",
    "                   hidden_units=16,\n",
    "                   output_shape=n_classes).to(device)\n",
    "\n",
    "loaded_model.load_state_dict(torch.load(f=\"./model.pth\"))\n",
    "\n",
    "# get results\n",
    "model_results = eval_func(data_loader=val_dataloader,\n",
    "                          model=loaded_model,\n",
    "                          loss_fn=loss_fn,\n",
    "                          accuracy_fn=accuracy_fn,\n",
    "                          device=device)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pjpVsjMIbcC"
   },
   "outputs": [],
   "source": [
    "# Get Model predictions and true targets\n",
    "y_targets = model_results['targets']\n",
    "y_preds = model_results['predictions']\n",
    "\n",
    "# Setup confusion matrix\n",
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\n",
    "confmat_tensor = confmat(preds=y_preds,\n",
    "                         target=y_targets)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fix, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(),\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9qdvhebId2u"
   },
   "outputs": [],
   "source": [
    "# Get Model predictions and true targets\n",
    "y_targets = model_results['targets']\n",
    "y_preds = model_results['predictions']\n",
    "\n",
    "# Setup confusion matrix\n",
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\n",
    "confmat_tensor = confmat(preds=y_preds,\n",
    "                         target=y_targets)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fix, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(),\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (scmil)",
   "language": "python",
   "name": "scmil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
